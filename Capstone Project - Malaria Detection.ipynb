{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification for Malaria Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing Necessary Libraries.\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout, Input, LSTM\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate empty lists for images\n",
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "#loop through folder with images and append to data, append 0 to labels for infected\n",
    "Infected=os.listdir(\"C:\\\\Users\\jonat\\Documents\\Python Scripts\\Coursera\\Advanced Data Science\\Applied AI\\cell_images\\Infected/\")\n",
    "for a in Infected:\n",
    "    try:\n",
    "        image=cv2.imread(\"C:\\\\Users\\jonat\\Documents\\Python Scripts\\Coursera\\Advanced Data Science\\Applied AI\\cell_images\\Infected/\" +a)\n",
    "        data.append(image)\n",
    "        labels.append(0)\n",
    "    except AttributeError:\n",
    "        print(\"\")\n",
    "        \n",
    "#loop through folder with images and append to data, append 1 to labels for uninfected\n",
    "Uninfected=os.listdir(\"C:\\\\Users\\jonat\\Documents\\Python Scripts\\Coursera\\Advanced Data Science\\Applied AI\\cell_images/Uninfected/\")\n",
    "for b in Uninfected:\n",
    "    try:\n",
    "        image=cv2.imread(\"C:\\\\Users\\jonat\\Documents\\Python Scripts\\Coursera\\Advanced Data Science\\Applied AI\\cell_images/Uninfected/\"+b)\n",
    "        data.append(image)\n",
    "        labels.append(1)\n",
    "    except AttributeError:\n",
    "        print(\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out None type objects\n",
    "- only 2 entries lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data  =[x for x in data if x is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = [i for i in range(len(data)) if data[i] is None]\n",
    "labels = [labels[i] for i in range(len(labels)) if i not in remove ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale images to equal size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled = []\n",
    "for image in data:\n",
    "    try:\n",
    "        image_from_array = Image.fromarray(image, 'RGB') \n",
    "        size_image = image_from_array.resize((50, 50)) # resize all images to 50,50\n",
    "        data_scaled.append(np.array(size_image)) # append to data_scaled list\n",
    "    except AttributeError:\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert lists to arrays\n",
    "data_scaled = np.array(data_scaled)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data so image import steps do not need to be re-run\n",
    "np.save('data', data)\n",
    "np.save('data_scaled', data_scaled)\n",
    "np.save('labels', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import saved data (so don't need to re-run image import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"data.npy\")\n",
    "data_scaled = np.load(\"data_scaled.npy\")\n",
    "labels=np.load(\"labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle data\n",
    "\n",
    "- Currently data is just Uninfected images appended to Infected images in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take current index\n",
    "shuffle_order =np.arange(data_scaled.shape[0])\n",
    "\n",
    "#shuffle index\n",
    "np.random.shuffle(shuffle_order)\n",
    "\n",
    "#apply shuffled indexing to arrays\n",
    "data_scaled=data_scaled[shuffle_order]\n",
    "labels=labels[shuffle_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Test and Control groups for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size =0.2\n",
    "\n",
    "x_train = data_scaled[:int(len(data_scaled)*(1-test_size))]\n",
    "x_test = data_scaled[int(len(data_scaled)*(1-test_size)):]\n",
    "\n",
    "y_train = labels[:int(len(labels)*(1-test_size))]\n",
    "y_test = labels[int(len(labels)*(1-test_size)):]\n",
    "\n",
    "train_len = len(x_train)\n",
    "test_len = len(x_test)\n",
    "\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#also want to keep a track of which index each \n",
    "shuffle_order_test = shuffle_order[int(len(shuffle_order)*(1-test_size)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22046,) (5512,)\n",
      "(22046, 50, 50, 3) (5512, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50, 50, 10)        40        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 25001     \n",
      "=================================================================\n",
      "Total params: 25,041\n",
      "Trainable params: 25,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "22046/22046 [==============================] - 13s 583us/step - loss: 8.0606 - acc: 0.4997\n",
      "Epoch 2/10\n",
      "22046/22046 [==============================] - 10s 432us/step - loss: 8.0576 - acc: 0.5001\n",
      "Epoch 3/10\n",
      "22046/22046 [==============================] - 24s 1ms/step - loss: 8.0576 - acc: 0.5001: 7s - loss: 8.1032 - acc: 0.4 - ETA: 8s - loss: - ETA: 10s - loss: 8.0861 - acc: 0. - ETA: 10s - loss: - ETA: 7s - loss: 8.077 - ETA: 6s - \n",
      "Epoch 4/10\n",
      "22046/22046 [==============================] - 12s 560us/step - loss: 8.0576 - acc: 0.5001\n",
      "Epoch 5/10\n",
      "22046/22046 [==============================] - 11s 480us/step - loss: 8.0576 - acc: 0.5001\n",
      "Epoch 6/10\n",
      "22046/22046 [==============================] - 10s 453us/step - loss: 8.0576 - acc: 0.5001\n",
      "Epoch 7/10\n",
      "22046/22046 [==============================] - 10s 432us/step - loss: 8.0576 - acc: 0.5001\n",
      "Epoch 8/10\n",
      "22046/22046 [==============================] - 9s 430us/step - loss: 8.0576 - acc: 0.5001\n",
      "Epoch 9/10\n",
      "22046/22046 [==============================] - 10s 437us/step - loss: 8.0576 - acc: 0.5001\n",
      "Epoch 10/10\n",
      "22046/22046 [==============================] - 9s 431us/step - loss: 8.0576 - acc: 0.5001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a7ff59ebe0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(10, activation='relu', input_shape=(50,50,3)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "model.fit(x=x_train, y=y_train, epochs=10, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimising Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 50, 50, 10)        40        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50, 50, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 50, 50, 16)        656       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 40000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                400010    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 400,717\n",
      "Trainable params: 400,717\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "22046/22046 [==============================] - 23s 1ms/step - loss: 0.6590 - acc: 0.6126\n",
      "Epoch 2/10\n",
      "22046/22046 [==============================] - 21s 953us/step - loss: 0.6147 - acc: 0.6665\n",
      "Epoch 3/10\n",
      "22046/22046 [==============================] - 21s 957us/step - loss: 0.5877 - acc: 0.6897\n",
      "Epoch 4/10\n",
      "22046/22046 [==============================] - 21s 956us/step - loss: 0.4830 - acc: 0.7831\n",
      "Epoch 5/10\n",
      "22046/22046 [==============================] - 21s 955us/step - loss: 0.3289 - acc: 0.8838\n",
      "Epoch 6/10\n",
      "22046/22046 [==============================] - 21s 967us/step - loss: 0.2707 - acc: 0.9094\n",
      "Epoch 7/10\n",
      "22046/22046 [==============================] - 22s 979us/step - loss: 0.2483 - acc: 0.9178\n",
      "Epoch 8/10\n",
      "22046/22046 [==============================] - 21s 961us/step - loss: 0.2353 - acc: 0.9228\n",
      "Epoch 9/10\n",
      "22046/22046 [==============================] - 21s 975us/step - loss: 0.2247 - acc: 0.9280\n",
      "Epoch 10/10\n",
      "22046/22046 [==============================] - 22s 995us/step - loss: 0.2156 - acc: 0.9320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a7ffdbe470>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add(Dense(10, activation='relu', input_shape=(50,50,3)))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=2,padding=\"same\",activation=\"relu\" ))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "model.fit(x=x_train, y=y_train, epochs=10, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.concatenate(model.predict_classes(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pd.DataFrame({'predictions':pred, 'actuals':y_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(y_pred=pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_pct = np.array([cm[0]/np.sum(cm[0]),cm[1]/np.sum(cm[1])])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "im = ax.imshow(cm_pct, interpolation='nearest', cmap='Blues')\n",
    "\n",
    "\n",
    "ax.set(xticks=np.arange(cm.shape[1]),\n",
    "       yticks=np.arange(cm.shape[0]),\n",
    "       # ... and label them with the respective list entries\n",
    "       xticklabels=['Uninfected','Infected'], yticklabels=['Uninfected','Infected']\n",
    "      ,title='Confusion Matrix');\n",
    "\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm_pct[i, j], '.2f')+'%',\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > cm.max()/2 else \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output images into separate folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "infected = []\n",
    "uninfected = []\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    if pred[i] == 0:\n",
    "        infected.append(data[shuffle_order_test[i]])\n",
    "    else:\n",
    "        uninfected.append(data[shuffle_order_test[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_infected = 'C:\\\\Users/jonat/Documents/Python Scripts/Coursera/Advanced Data Science/Applied AI/output/infected'\n",
    "path_uninfected = 'C:\\\\Users/jonat/Documents/Python Scripts/Coursera/Advanced Data Science/Applied AI/output/uninfected'\n",
    "\n",
    "for i in range(len(infected)):\n",
    "    cv2.imwrite(os.path.join(path_infected , str(i)+'_infected.jpg'), infected[i])\n",
    "\n",
    "for i in range(len(uninfected)):\n",
    "    cv2.imwrite(os.path.join(path_uninfected , str(i)+'_uninfected.jpg'), uninfected[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
